{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bieZD8966__g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e59bbf92-4ee3-401b-8c01-86925fa89b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        " # Conect to google drive\n",
        "# [Do not modified this code]\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oh3Og7naIP5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca5f8aff-8b01-44e4-aea9-9290dab24543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI_HW1\n",
            "fatal: destination path 'ImageBind' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Download ImageBind\n",
        "# [Do not modified this code]\n",
        "%cd /content/drive/MyDrive/AI_HW1\n",
        "!git clone https://github.com/facebookresearch/ImageBind.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot-CwooUIk-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd59e42-0860-4cc9-c3e6-ef3ae3ba3b2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: './ImageBind'\n",
            "/content/drive/MyDrive/AI_HW1/ImageBind\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Processing /content/drive/MyDrive/AI_HW1/ImageBind\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorchvideo@ git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d (from imagebind==0.1.0)\n",
            "  Cloning https://github.com/facebookresearch/pytorchvideo.git (to revision 28fe037d212663c6a24f373b94cc5d478c8c1a1d) to /tmp/pip-install-psami3yy/pytorchvideo_79a403bf405f4a1d8c9ab745c68c1cb3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorchvideo.git /tmp/pip-install-psami3yy/pytorchvideo_79a403bf405f4a1d8c9ab745c68c1cb3\n",
            "  Running command git rev-parse -q --verify 'sha^28fe037d212663c6a24f373b94cc5d478c8c1a1d'\n",
            "  Running command git fetch -q https://github.com/facebookresearch/pytorchvideo.git 28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
            "  Running command git checkout -q 28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
            "  Resolved https://github.com/facebookresearch/pytorchvideo.git to commit 28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch==1.13.0 (from imagebind==0.1.0)\n",
            "  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.2/890.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
            "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
            "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\n",
            "    data = self.__fp.read(amt)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 466, in read\n",
            "    s = self.fp.read(amt)\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1274, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1130, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "TimeoutError: The read operation timed out\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 92, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_updated_criteria(candidate)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 230, in _get_updated_criteria\n",
            "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
            "    if not criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n",
            "    return bool(self._sequence)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n",
            "    return any(self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n",
            "    candidate = func()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 293, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 225, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 304, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 516, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 587, in _prepare_linked_requirement\n",
            "    local_file = unpack_url(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 166, in unpack_url\n",
            "    file = get_http_url(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 107, in get_http_url\n",
            "    from_path, content_type = download(link, temp_dir.path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/network/download.py\", line 147, in __call__\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
            "    for chunk in iterable:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
            "    for chunk in response.raw.stream(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
            "    with self._error_catcher():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
            "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
            "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Build Environment\n",
        "# [Do not modified this code]\n",
        "%cd ./ImageBind\n",
        "!pip install torch==2.0.1\n",
        "!pip install ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model\n",
        "# [Do not modify this code]\n",
        "\n",
        "%cd /content/drive/MyDrive/AI_HW1/ImageBind\n",
        "!pip install pytorchvideo\n",
        "!pip install ftfy\n",
        "!pip install timm\n",
        "!pip install einops\n",
        "\n",
        "from imagebind import data\n",
        "import torch\n",
        "from imagebind.models import imagebind_model\n",
        "from imagebind.models.imagebind_model import ModalityType\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Instantiate model\n",
        "model = imagebind_model.imagebind_huge(pretrained=True)\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "V_pVJ6QH84pL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d5eef1-49bf-4f6f-cff6-bcdedd11ae2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI_HW1/ImageBind\n",
            "Collecting pytorchvideo\n",
            "  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fvcore (from pytorchvideo)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av (from pytorchvideo)\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parameterized (from pytorchvideo)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting iopath (from pytorchvideo)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (1.23.5)\n",
            "Collecting yacs>=0.1.6 (from fvcore->pytorchvideo)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (4.66.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (2.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (0.9.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath->pytorchvideo) (4.5.0)\n",
            "Collecting portalocker (from iopath->pytorchvideo)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: pytorchvideo, fvcore, iopath\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188685 sha256=269a272e7f12806264622baa72e4fd3bb44b1c5c13e13d7b4b119025fd15ca19\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/4e/81/0f72a543be9ed7eb737c95bfc5da4025e73226b44368074ece\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=5697124eeb33f21d87b9183823e086b237170f37706847f5b728e89d6b78010b\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31530 sha256=b0ba9b76fe0c081cbdac1e395936e8e7734a890cf9130ccb38005a633bf0d472\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built pytorchvideo fvcore iopath\n",
            "Installing collected packages: av, yacs, portalocker, parameterized, iopath, fvcore, pytorchvideo\n",
            "Successfully installed av-10.0.0 fvcore-0.1.5.post20221221 iopath-0.1.10 parameterized-0.9.0 portalocker-2.8.2 pytorchvideo-0.1.5 yacs-0.1.8\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.6)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.1\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.17.2 safetensors-0.3.3 timm-0.9.7\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading imagebind weights to .checkpoints/imagebind_huge.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.47G/4.47G [01:14<00:00, 64.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageBindModel(\n",
              "  (modality_preprocessors): ModuleDict(\n",
              "    (vision): RGBDTPreprocessor(\n",
              "      (cls_token): tensor((1, 1, 1280), requires_grad=True)\n",
              "      \n",
              "      (rgbt_stem): PatchEmbedGeneric(\n",
              "        (proj): Sequential(\n",
              "          (0): PadIm2Video()\n",
              "          (1): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
              "        (pos_embed): tensor((1, 257, 1280), requires_grad=True)\n",
              "        \n",
              "      )\n",
              "    )\n",
              "    (text): TextPreprocessor(\n",
              "      (pos_embed): tensor((1, 77, 1024), requires_grad=True)\n",
              "      (mask): tensor((77, 77), requires_grad=False)\n",
              "      \n",
              "      (token_embedding): Embedding(49408, 1024)\n",
              "    )\n",
              "    (audio): AudioPreprocessor(\n",
              "      (cls_token): tensor((1, 1, 768), requires_grad=True)\n",
              "      \n",
              "      (rgbt_stem): PatchEmbedGeneric(\n",
              "        (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10), bias=False)\n",
              "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
              "        (pos_embed): tensor((1, 229, 768), requires_grad=True)\n",
              "        \n",
              "      )\n",
              "    )\n",
              "    (depth): RGBDTPreprocessor(\n",
              "      (cls_token): tensor((1, 1, 384), requires_grad=True)\n",
              "      \n",
              "      (depth_stem): PatchEmbedGeneric(\n",
              "        (proj): Conv2d(1, 384, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
              "        (norm_layer): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
              "        (pos_embed): tensor((1, 197, 384), requires_grad=True)\n",
              "        \n",
              "      )\n",
              "    )\n",
              "    (thermal): ThermalPreprocessor(\n",
              "      (cls_token): tensor((1, 1, 768), requires_grad=True)\n",
              "      \n",
              "      (rgbt_stem): PatchEmbedGeneric(\n",
              "        (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
              "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
              "        (pos_embed): tensor((1, 197, 768), requires_grad=True)\n",
              "        \n",
              "      )\n",
              "    )\n",
              "    (imu): IMUPreprocessor(\n",
              "      (pos_embed): tensor((1, 251, 512), requires_grad=True)\n",
              "      (cls_token): tensor((1, 1, 512), requires_grad=True)\n",
              "      \n",
              "      (imu_stem): PatchEmbedGeneric(\n",
              "        (proj): Linear(in_features=48, out_features=512, bias=False)\n",
              "        (norm_layer): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (modality_trunks): ModuleDict(\n",
              "    (vision): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (12): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (13): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (14): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (15): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (16): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (17): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (18): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (19): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (20): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (21): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (22): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (23): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (24): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (25): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (26): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (27): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (28): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (29): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (30): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (31): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (text): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (12): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (13): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (14): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (15): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (16): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (17): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (18): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (19): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (20): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (21): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (22): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (23): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (audio): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.009)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.018)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.027)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.036)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.045)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.055)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.064)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.073)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.082)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.091)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.100)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (depth): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (thermal): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (imu): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.140)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.280)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.420)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.560)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.700)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "  )\n",
              "  (modality_heads): ModuleDict(\n",
              "    (vision): Sequential(\n",
              "      (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Linear(in_features=1280, out_features=1024, bias=False)\n",
              "    )\n",
              "    (text): SelectEOSAndProject(\n",
              "      (proj): Sequential(\n",
              "        (0): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (1): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "      )\n",
              "    )\n",
              "    (audio): Sequential(\n",
              "      (0): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Linear(in_features=768, out_features=1024, bias=False)\n",
              "    )\n",
              "    (depth): Sequential(\n",
              "      (0): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Linear(in_features=384, out_features=1024, bias=False)\n",
              "    )\n",
              "    (thermal): Sequential(\n",
              "      (0): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Linear(in_features=768, out_features=1024, bias=False)\n",
              "    )\n",
              "    (imu): Sequential(\n",
              "      (0): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=512, out_features=1024, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (modality_postprocessors): ModuleDict(\n",
              "    (vision): Normalize()\n",
              "    (text): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=14.285714285714285,learnable=True, max_logit_scale=100)\n",
              "    )\n",
              "    (audio): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=20.0,learnable=False, max_logit_scale=100)\n",
              "    )\n",
              "    (depth): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=5.0,learnable=False, max_logit_scale=100)\n",
              "    )\n",
              "    (thermal): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=10.0,learnable=False, max_logit_scale=100)\n",
              "    )\n",
              "    (imu): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=5.0,learnable=False, max_logit_scale=100)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahQ7Z1Y-Mcx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59096d83-e0ee-4f95-bdb0-c3cba3cd4399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vision x Text:  tensor([[9.8360e-01, 1.6274e-02, 1.2784e-04],\n",
            "        [4.6024e-06, 9.9997e-01, 2.4119e-05],\n",
            "        [1.3127e-05, 1.3497e-02, 9.8649e-01]], device='cuda:0')\n",
            "Audio x Text:  tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]], device='cuda:0')\n",
            "Vision x Audio:  tensor([[0.8070, 0.1088, 0.0842],\n",
            "        [0.1036, 0.7884, 0.1079],\n",
            "        [0.0018, 0.0022, 0.9960]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Sample Code\n",
        "text_list=[\"A dog\", \"A car\", \"A bird\"]\n",
        "image_paths=[\".assets/dog_image.jpg\", \".assets/car_image.jpg\", \".assets/bird_image.jpg\"]\n",
        "audio_paths=[\".assets/dog_audio.wav\", \".assets/car_audio.wav\", \".assets/bird_audio.wav\"]\n",
        "\n",
        "inputs = {\n",
        "    ModalityType.TEXT: data.load_and_transform_text(text_list, device),\n",
        "    ModalityType.VISION: data.load_and_transform_vision_data(image_paths, device),\n",
        "    ModalityType.AUDIO: data.load_and_transform_audio_data(audio_paths, device),\n",
        "}\n",
        "\n",
        "with torch.no_grad():\n",
        "    embeddings = model(inputs)\n",
        "\n",
        "print(\n",
        "    \"Vision x Text: \",\n",
        "    torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.TEXT].T, dim=-1),\n",
        ")\n",
        "print(\n",
        "    \"Audio x Text: \",\n",
        "    torch.softmax(embeddings[ModalityType.AUDIO] @ embeddings[ModalityType.TEXT].T, dim=-1),\n",
        ")\n",
        "print(\n",
        "    \"Vision x Audio: \",\n",
        "    torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.AUDIO].T, dim=-1),\n",
        ")\n",
        "\n",
        "# Expected output:\n",
        "#\n",
        "# Vision x Text:\n",
        "# tensor([[9.9761e-01, 2.3694e-03, 1.8612e-05],\n",
        "#         [3.3836e-05, 9.9994e-01, 2.4118e-05],\n",
        "#         [4.7997e-05, 1.3496e-02, 9.8646e-01]])\n",
        "#\n",
        "# Audio x Text:\n",
        "# tensor([[1., 0., 0.],\n",
        "#         [0., 1., 0.],\n",
        "#         [0., 0., 1.]])\n",
        "#\n",
        "# Vision x Audio:\n",
        "# tensor([[0.8070, 0.1088, 0.0842],\n",
        "#         [0.1036, 0.7884, 0.1079],\n",
        "#         [0.0018, 0.0022, 0.9960]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Refer to the above sample code, load the image data for the text, and and generates its embedding\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/AI_HW1/'\n",
        "text_list=[\"Dog\", \"Car\", \"Bird\"]\n",
        "\n",
        "# TODO: Choose one picture for each category and generates an embedding(5%)\n",
        "# Please output the result as embeddings, like the sample code\n",
        "image_paths=[ file_path+text_list[0]+\"/image_001.jpg\", file_path+text_list[1]+\"/image_001.jpg\", file_path+text_list[2]+\"/image_001.jpg\"]\n",
        "\n",
        "inputs = {\n",
        "    ModalityType.TEXT: data.load_and_transform_text(text_list, device),\n",
        "    ModalityType.VISION: data.load_and_transform_vision_data(image_paths, device),\n",
        "}\n",
        "\n",
        "with torch.no_grad():\n",
        "    embeddings = model(inputs)\n",
        "\n",
        "print(\n",
        "    \"Vision x Text: \",\n",
        "    torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.TEXT].T, dim=-1),\n",
        ")"
      ],
      "metadata": {
        "id": "2cqKV9mmF0d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e40a32-28df-4127-9a49-213f6d41d50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vision x Text:  tensor([[9.9974e-01, 2.5731e-04, 6.1573e-06],\n",
            "        [9.8385e-05, 9.9986e-01, 3.8284e-05],\n",
            "        [8.1904e-07, 9.1834e-07, 1.0000e+00]], device='cuda:0')\n",
            "Audio x Text:  tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]], device='cuda:0')\n",
            "Vision x Audio:  tensor([[1.5110e-01, 2.8737e-02, 8.2016e-01],\n",
            "        [8.2650e-03, 8.4849e-01, 1.4324e-01],\n",
            "        [2.9872e-05, 3.3165e-04, 9.9964e-01]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save　the embeddings\n",
        "import pickle\n",
        "with open('embeddings_0922.pickle', 'wb') as file:\n",
        "    pickle.dump(embeddings, file)\n",
        "\n"
      ],
      "metadata": {
        "id": "gqCCW8XgUdNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSq-T4gyYo4L",
        "outputId": "2a211a02-71bc-4e0f-8dde-701bfeb5c4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/AI_HW1/ImageBind\n",
        "\n",
        "import pickle\n",
        "# when embeddings is needed\n",
        "with open('embeddings_0922.pickle', 'rb') as file:\n",
        "    embeddings = pickle.load(file)"
      ],
      "metadata": {
        "id": "NLv2AVkufyRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad22b15-29ff-494a-bdeb-04e38a818b69"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI_HW1/ImageBind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch==2.0.1\n",
        "# !pip install .\n",
        "\n",
        "from imagebind import data\n",
        "import torch\n",
        "from imagebind.models import imagebind_model\n",
        "from imagebind.models.imagebind_model import ModalityType\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def build_dot_product_matrix(embeddings):\n",
        "  # TODO: build 3*3 matrixes (inner product, softmax of inner product) of the pictures (5%)\n",
        "  dot_product_matrix = embeddings[ModalityType.VISION] @ embeddings[ModalityType.TEXT].T\n",
        "  softmax_matrix = torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.TEXT].T, dim=-1),\n",
        "\n",
        "  return dot_product_matrix, softmax_matrix[0]\n",
        "\n",
        "dot_product_matrix, softmax_matrix = build_dot_product_matrix(embeddings) # The embedding that generates above\n",
        "\n",
        "row_labels = [\"Dog\", \"Car\", \"Bird\"]\n",
        "column_labels = [\"Dog\", \"Car\", \"Bird\"]\n",
        "\n",
        "dot_product_pd = pd.DataFrame(dot_product_matrix.cpu().numpy(), index=row_labels, columns=column_labels)\n",
        "softmax_matrix_pd = pd.DataFrame(softmax_matrix.cpu().numpy(), index=row_labels, columns=column_labels)\n",
        "\n",
        "pd.options.display.float_format = '{:.8f}'.format\n",
        "\n",
        "print(\"Dot Product Matrix:\")\n",
        "print(dot_product_pd)\n",
        "\n",
        "print(\"Softmax Matrix:\")\n",
        "print(softmax_matrix_pd)"
      ],
      "metadata": {
        "id": "USz7OmEsrYv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e250014-593e-4874-ec82-8532f28c0cea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dot Product Matrix:\n",
            "             Dog         Car        Bird\n",
            "Dog  24.35992432 16.09494781 12.36231804\n",
            "Car   9.13704777 18.36353111  8.19318676\n",
            "Bird 10.50400162 10.61843777 24.51913071\n",
            "Softmax Matrix:\n",
            "            Dog        Car       Bird\n",
            "Dog  0.99973649 0.00025731 0.00000616\n",
            "Car  0.00009839 0.99986327 0.00003828\n",
            "Bird 0.00000082 0.00000092 0.99999821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbA5lOC5kuEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf8be9ad-290c-4899-d4ce-7c3b489cc33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Product Matrix:\n",
            "            Dog        Car       Bird\n",
            "Dog  0.24359924 0.16094951 0.12362319\n",
            "Car  0.09137049 0.18363532 0.08193187\n",
            "Bird 0.10504004 0.10618439 0.24519134\n"
          ]
        }
      ],
      "source": [
        "# Use cosine_similarity in sklearn to process the embeddings\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def build_dot_cosine_matrix(embeddings):\n",
        "  #  TODO: build 3*3 matrixes (cosine similarity) of the pictures  (5%)\n",
        "  result_cosine_matrix = cosine_similarity(embeddings[ModalityType.VISION].cpu(), embeddings[ModalityType.TEXT].cpu())\n",
        "  return result_cosine_matrix\n",
        "\n",
        "cosine_matrix = build_dot_cosine_matrix(embeddings) # The embedding that generates above\n",
        "\n",
        "row_labels = [\"Dog\", \"Car\", \"Bird\"]\n",
        "column_labels = [\"Dog\", \"Car\", \"Bird\"]\n",
        "\n",
        "cosine_product_pd = pd.DataFrame(cosine_matrix, index=row_labels, columns=column_labels)\n",
        "\n",
        "print(\"Cosine Product Matrix:\")\n",
        "print(cosine_product_pd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cE5_eigjauFw"
      },
      "outputs": [],
      "source": [
        "def load_data_from_folder(path):\n",
        "  image_paths = []\n",
        "  image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp']\n",
        "  for root, dirs, files in os.walk(path):\n",
        "    for file in files:\n",
        "        _, extension = os.path.splitext(file)\n",
        "        if extension.lower() in image_extensions:\n",
        "            image_paths.append(os.path.join(root, file))\n",
        "  return image_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KmBTEQdhT3OA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14edd7fa-53a4-4433-ab8b-ca42b1a2bef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/AI_HW1/Dog/image_003.jpg', '/content/drive/MyDrive/AI_HW1/Dog/image_005.jpg', '/content/drive/MyDrive/AI_HW1/Dog/image_010.jpg', '/content/drive/MyDrive/AI_HW1/Dog/image_002.jpg', '/content/drive/MyDrive/AI_HW1/Dog/image_004.jpg', '/content/drive/MyDrive/AI_HW1/Dog/image_007.jpg', '/content/drive/MyDrive/AI_HW1/Dog/image_006.jpg', '/content/drive/MyDrive/AI_HW1/Dog/image_009.jpg', '/content/drive/MyDrive/AI_HW1/Dog/image_008.jpg', '/content/drive/MyDrive/AI_HW1/Dog/image_001.jpg']\n",
            "10\n",
            "10\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# model = imagebind_model.imagebind_huge(pretrained=True)\n",
        "# model.eval()\n",
        "# model.to(device)\n",
        "\n",
        "dog_folder_path = '/content/drive/MyDrive/AI_HW1/Dog'\n",
        "car_folder_path = '/content/drive/MyDrive/AI_HW1/Car'\n",
        "bird_folder_path = '/content/drive/MyDrive/AI_HW1/Bird'\n",
        "\n",
        "dog_text = \"Dog\"\n",
        "car_text = \"Car\"\n",
        "bird_text = \"Bird\"\n",
        "\n",
        "dog_image_paths = load_data_from_folder(dog_folder_path)\n",
        "print(dog_image_paths)\n",
        "car_image_paths = load_data_from_folder(car_folder_path)\n",
        "bird_image_paths = load_data_from_folder(bird_folder_path)\n",
        "\n",
        "# TODO: Transform Vision Data (3%)\n",
        "# TODO: Transform Text Data (3%)\n",
        "\n",
        "\n",
        "# TODO: Generate embeddings for each set of catogories data (4%)\n",
        "dog_embeddings = []\n",
        "for image_path in dog_image_paths:\n",
        "    dog_inputs = {\n",
        "    ModalityType.TEXT: data.load_and_transform_text(dog_text, device),\n",
        "    ModalityType.VISION: data.load_and_transform_vision_data([image_path], device),\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        embedding = model(dog_inputs)\n",
        "        dog_embeddings.append(embedding)\n",
        "\n",
        "dog_embeddings = np.array(dog_embeddings)\n",
        "print(len(dog_embeddings))\n",
        "\n",
        "car_embeddings = []\n",
        "for image_path in car_image_paths:\n",
        "    car_inputs = {\n",
        "    ModalityType.TEXT: data.load_and_transform_text(car_text, device),\n",
        "    ModalityType.VISION: data.load_and_transform_vision_data([image_path], device),\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        embedding = model(car_inputs)\n",
        "        car_embeddings.append(embedding)\n",
        "\n",
        "car_embeddings = np.array(car_embeddings)\n",
        "print(len(car_embeddings))\n",
        "\n",
        "bird_embeddings = []\n",
        "for image_path in bird_image_paths:\n",
        "    bird_inputs = {\n",
        "    ModalityType.TEXT: data.load_and_transform_text(bird_text, device),\n",
        "    ModalityType.VISION: data.load_and_transform_vision_data([image_path], device),\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        embedding = model(bird_inputs)\n",
        "        bird_embeddings.append(embedding)\n",
        "\n",
        "bird_embeddings = np.array(bird_embeddings)\n",
        "print(len(bird_embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TODO: Implement TSNE (10%)\n",
        "# [HINT] Use sk-learn tsne\n",
        "# [HINT] Cat all the emnedding from each catafories together, and create a label list for them\n",
        "# [HINT] Run TSNE and display the result\n",
        "\n",
        "# Concatenate the embeddings\n",
        "dog_vision_embeddings = np.concatenate([embedding['vision'].cpu().numpy() for embedding in dog_embeddings])\n",
        "car_vision_embeddings = np.concatenate([embedding['vision'].cpu().numpy() for embedding in car_embeddings])\n",
        "bird_vision_embeddings = np.concatenate([embedding['vision'].cpu().numpy() for embedding in bird_embeddings])\n",
        "\n",
        "# Concatenate the vision embeddings along the rows\n",
        "all_embeddings = np.concatenate((dog_vision_embeddings, car_vision_embeddings, bird_vision_embeddings), axis=0)\n",
        "print(all_embeddings)\n",
        "\n",
        "# Create labels for the embeddings based on their category (0 for dogs, 1 for cars, 2 for birds)\n",
        "labels = np.concatenate((np.zeros(10), np.ones(10), 2*np.ones(10)))\n",
        "\n",
        "# Initialize t-SNE\n",
        "tsne = TSNE(n_components=2, perplexity=2, random_state=0)  # You can adjust the number of components as needed\n",
        "\n",
        "# Fit t-SNE to the concatenated embeddings\n",
        "tsne_results = tsne.fit_transform(all_embeddings)\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels)\n",
        "# plt.legend(labels=['Dog', 'Car', 'Bird'])\n",
        "\n",
        "plt.title('t-SNE Visualization of Image Embeddings (perplexity=2)')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p_6Hd0JBthmD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "4725bdd4-b32f-43ad-e2af-b0ee6b44aa08"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.03044795  0.00209353  0.01168272 ...  0.04274828  0.00669835\n",
            "   0.01462938]\n",
            " [-0.04888483 -0.02292984  0.00466948 ... -0.00210962  0.01726878\n",
            "   0.01438465]\n",
            " [-0.03338646 -0.02851862  0.0061971  ...  0.00727116  0.01474715\n",
            "   0.01021104]\n",
            " ...\n",
            " [-0.03179081 -0.03289419 -0.00138299 ...  0.00297725  0.01155705\n",
            "  -0.01236649]\n",
            " [ 0.0084438  -0.03680404  0.02594535 ...  0.02231183  0.02370724\n",
            "   0.02407025]\n",
            " [-0.00634704 -0.01987046  0.03845118 ...  0.01385444 -0.02177603\n",
            "   0.00959224]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW6846kxs3g1"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# class PCA:\n",
        "#     def __init__(self, n_components: int):\n",
        "#         self.n_components = n_components\n",
        "#         self.mean = None\n",
        "#         self.components = None\n",
        "\n",
        "#     def fit(self, X: np.ndarray):\n",
        "#         # TODO: 10%\n",
        "#         # [Hint] Calculate covariance matrix and its eigenvalues and eigenvectors\n",
        "\n",
        "#     def transform(self, X: np.ndarray) -> np.ndarray:\n",
        "#         # TODO: 5%\n",
        "#         # [Hint] Use the priciple components calculated in the previous method the project the transformed data\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class PCA:\n",
        "    def __init__(self, n_components: int):\n",
        "        self.n_components = n_components\n",
        "        self.mean = None\n",
        "        self.components = None\n",
        "\n",
        "    def fit(self, X: np.ndarray):\n",
        "        # TODO: 10%\n",
        "        # [Hint] Calculate covariance matrix and its eigenvalues and eigenvectors\n",
        "        self.mean = np.mean(X, axis=0)\n",
        "        centered_data = X - self.mean\n",
        "        covariance_matrix = np.cov(centered_data, rowvar=False)\n",
        "        eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
        "        sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "        eigenvalues = eigenvalues[sorted_indices]\n",
        "        eigenvectors = eigenvectors[:, sorted_indices]\n",
        "        self.components = eigenvectors[:, :self.n_components]\n",
        "\n",
        "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
        "        # TODO: 5%\n",
        "        # [Hint] Use the priciple components calculated in the previous method the project the transformed data\n",
        "        centered_data = X - self.mean\n",
        "        transformed_data = np.dot(centered_data, self.components)\n",
        "        return transformed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_fv-K8fl0yk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "617f047e-b730-4e82-ba94-b76237abe72f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# TODO: Implement PCA (10%)\n",
        "# [HINT] Cat all the emnedding from each catafories together\n",
        "# [HINT] Run PCA and display the result\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(all_embeddings)\n",
        "pca_result = pca.transform(all_embeddings)\n",
        "labels = np.concatenate((np.zeros(10), np.ones(10), 2*np.ones(10)))\n",
        "\n",
        "# Output the result as pca_result, and labels as labels\n",
        "\n",
        "# Plotting\n",
        "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=labels)\n",
        "plt.title('PCA Visualization of Image Embeddings')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IbmfHdkzdVyn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "64a4206c-81f2-4f1e-87d2-692159642dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vision x Text:  tensor([[1.0000e+00, 6.1386e-07, 4.2893e-08],\n",
            "        [2.3189e-05, 9.9319e-01, 6.7895e-03],\n",
            "        [2.1998e-02, 5.0092e-03, 9.7299e-01]])\n",
            "Dot Product Matrix:\n",
            "           Dog       Car      Bird\n",
            "Dog  24.359924 16.094948 12.362318\n",
            "Car   9.137048 18.363531  8.193187\n",
            "Bird 10.504002 10.618438 24.519131\n",
            "Softmax Matrix:\n",
            "          Dog      Car     Bird\n",
            "Dog  0.999999 0.000001 0.000000\n",
            "Car  0.000023 0.993187 0.006790\n",
            "Bird 0.021998 0.005009 0.972993\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Describe the pictures with your creativity! (5%)\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/AI_HW1/Cat/'\n",
        "\n",
        "# TODO: Choose one picture for each category and generates an embedding(5%)\n",
        "# Please output the result as embeddings, like the sample code\n",
        "image_paths=[ file_path+\"/cat_with_rabbit_headwear.jpg\", file_path+\"/standing_cat.jpg\", file_path+\"/stacking_cats.jpg\"]\n",
        "text_list = [\"A cat with rabbit headwear\", \"A standing cat\", \"Stacking Cats\"]\n",
        "\n",
        "inputs = {\n",
        "    ModalityType.TEXT: data.load_and_transform_text(text_list, device),\n",
        "    ModalityType.VISION: data.load_and_transform_vision_data(image_paths, device),\n",
        "}\n",
        "\n",
        "with torch.no_grad():\n",
        "    embeddings = model(inputs)\n",
        "\n",
        "softmax_matrix = torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.TEXT].T, dim=-1).cpu()\n",
        "\n",
        "print(\"Vision x Text: \", softmax_matrix)\n",
        "\n",
        "dot_product_pd = pd.DataFrame(dot_product_matrix.cpu().numpy(), index=row_labels, columns=column_labels)\n",
        "softmax_matrix_pd = pd.DataFrame(softmax_matrix.cpu().numpy(), index=row_labels, columns=column_labels)\n",
        "\n",
        "pd.options.display.float_format = '{:.6f}'.format\n",
        "\n",
        "print(\"Dot Product Matrix:\")\n",
        "print(dot_product_pd)\n",
        "\n",
        "print(\"Softmax Matrix:\")\n",
        "print(softmax_matrix_pd)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(softmax_matrix, cmap='Blues')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}